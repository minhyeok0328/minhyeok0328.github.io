---
title: "이어드림 스쿨 DE 미니 프로젝트 후기"
date: 2024-08-08 12:00:00 +0900
categories: [yeardream]
tags: [airflow, kafka, grafana, prometheus, spark, postgresql, elasticsearch, kibana]
---

# 이어드림 스쿨 미니 프로젝트 후기

3월부터 이어드림 스쿨 과정에 참여하며 처음으로 제대로 된 팀 프로젝트인 데이터 엔지니어링 미니 프로젝트에 대한 후기를 작성해 보려 한다.

# 프로젝트 주제

![프로젝트 진행 프로세스](https://github.com/user-attachments/assets/c35f0151-d1ff-49d0-b914-1745aff0e8de)

말 그대로 데이터 엔지니어링 프로젝트이다.

5월 초에 DS, DE트랙 분반을 한 이후 수업에서 배운 내용들을 바탕으로 각 팀별로 자유롭게 데이터 파이프라인을 만드는 프로젝트를 진행했다.

뭔가 리더 한 번 해보고 싶어서 자원했는데 지원자가 나 뿐이라 그대로 리더가 되었다. (어라)

팀 발표되고 주제 토론 하다가 어떤 분이 스팀 API 가지고 만들어보자고 의견 내줬는데 맘에 들어서 그거로 정해졌다.


# 프로젝트 개요
> Steam Web API에서 게임 별 뉴스, 최근 플레이한 게임, 동시접속자 수 등의 데이터를 바탕으로 유의미한 데이터르 수집하는 파이프라인 구축 및 시각화

프로젝트 내용을 요약하자면 이렇다.

[Steam Web API](https://partner.steamgames.com/doc/webapi)

![steam web api list](https://github.com/user-attachments/assets/b5bdce58-6b1f-4434-a481-6252724eb550)

여러가지의 api들이 있고 우리는 ISteamNews, ISteamUser* 등의 API 위주로 사용했다.

평소 스팀에서 게임 많이 하는데 정작 이런 API 찾아볼 생각은 안했어서 생각했던 것 보다 재미있었다.


# Data Pipeline Structure

![데이터 파이프라인 구조](https://github.com/user-attachments/assets/42350d87-48e4-4af0-99da-1dd91c8a7be8)

데이터 파이프라인의 구조는 이렇다.

아래에서 상세하게 설명하겠지만 간략이 요약하자면,

1. Airflow에서 Steam Web API에서 제공하는 Json 데이터를 배치잡으로 가져온다.
2. 가져온 데이터를 Kafka로 스트리밍 한다.
   - Prometheus, Grafana로 Kafka를 모니터링 한다
3. 각 앱에서 컨슈밍 해간다
   - 전처리가 필요한 데이터는 Spark에서, 필요 없다고 판단된 데이터는 Elastic Search에 있는 Kafka Connector를 통해 바로 넣어준다.
   - Elastic Search에 넣기 전 데이터들은 PostgreSQL(백업용)에 동시에 insert 해준다
4. Kibana를 Elastic Search를 바라보게 구성한 뒤 시각화 한다.
5. 모든 서비스는 Docker Container로 띄웠다.

우선 AWS EC2에서 구축했고, t2.xlarge 인스턴스 3개를 제공받았고 이 위에서 파이프라인을 구축했다.

왜 이렇게 구성했는지 살펴보자면

## Steam API를 Airflow를 통해 가져오자

### Airflow를 선택한 이유

![Airflow 작동중인 화면](https://github.com/user-attachments/assets/c8a7d65a-64cc-426b-a5f9-8386a5b9d334)

실시간 데이터들은 없었다.
그리고 가져와야 하는 데이터들의 주기도 각각 달랐다.

예를 들어 게임 같은 경우는 패치를 하루 몇 수십번 씩 하는 건 없다시피 하고 많아야 하루 한 번 꼴로 패치나 소식들을 업데이트 한다.

반면에 최근 플레이 목록은 1분 주기로 자주 가져오면서 동시에 유저가 해당 게임을 몇 시간이나 플레이 했는지도 알 수 있기 때문에 자주 가져온다.

각각 데이터를 가져오는 주기가 다르기 때문에 Airflow를 활용해서 데이터 수집을 하기로 했다.

### 아쉬웠던 점

우리가 만든 데이터 파이프라인 에서는 Airflow를 단순 배치잡 + Kafka로 데이터 스트리밍 하는 용도로 쓴게 조금 아쉽긴 하다.

데이터 레이크에 담긴 데이터들을 데이터 웨어하우스로 혹은 마트 테이블로 만드는 과정의 task들을 구성해 봤으면 좀 더 도움이 되었을 것 같다. (이어드림 스쿨 aws 계정에 S3 권한도 열려있던 걸 뒤늦게 본건 안 비밀)

Parquet 파일로 s3 버킷에 저장해서 데이터 웨어하우스 구축하고 그걸 바탕으로 데이터 마트를 만든 뒤 마트에서 Spark로 데이터 가져와서 분석 및 시각화를 해봤으면 어땠을까? 라는 생각이 든다.

지금 구조는 백업 이외에 따로 데이터 웨어하우스를 만든다거나 하지는 않고 바로 Elastic Search에 저장되는 단순한 구조이기 때문이다.


## Kafka Cluster를 구축해서 데이터를 스트리밍 해보자
### Kafka를 선택한 이유

Airflow에서 가져온 데이터를 프로듀싱 해야했고 여러 앱들이 데이터를 컨슈밍 할 수 있도록 관리 해줄 수 있는게 필요했기 때문에 해당 역할은 분산 스트리밍 플랫폼인 Kafka를 사용하는 것으로 결정했다.


### 왜 Zookeeper를 쓰지 않았나요?

먼저 Zookeeper에 대해 설명하자면,

일단 하둡 에코시스템에서 보던 친구이다 (안녕)

Kafka의 Broker, Topic, Partition 등의 Metadata 들을 관리해 준다.

내가 느꼇던 큰 문제는 아래와 같다.

1. Kafka에게 자원 할당 해주는 역할이 외부(Zookeeper)에 위임되어 있다.
   - 이는 Zookeeper가 죽었을 때 Kafka는 발만 동동 굴러야 한다는 얘기이다. Kafka는 실시간 스트리밍 플랫폼인데 장애조치가 즉각적으로 되지 않는 다는 건 문제가 있다.
   - 예를 들어 카카오맵에서 생기는 실시간 지도 gps 데이터 같은 건 좀 날라가도 괜찮겠지만, 결제 시스템, 주식거래 등 중요한 데이터를 스트리밍 할 때는 문제가 있다고 생각한다.
2. 관리하기 힘들다.
   - Kafka Cluster도 관리하기 까다로운데, Zookeeper까지 모니터링 해야하니 관리자 입장에서는 골치 아파진다.
   - 많은 노드를 지원하려면 Zookeeper쪽에 성능 문제도 고려해야 한다.

그래서 원래는 Zookeeper와 Kafka를 같이 사용했지만,

Apache Kafka는 Zookeeper에 대한 종속성을 제거하기로 결정하고 새로운 합의 프로토콜로 KRaft라는 게 나왔고, 기존 방식보다 장점이 많다고 생각했다.

### 그럼 KRaft Mode의 장점은 뭔가요?

**Kafka with Zookeeper**랑 비교해보면

1. 구조 단순화
   - Zookeeper 없이 Kafka만 단독으로 운영하면 된다.
   - 구조가 단순해졌으니, 클러스터 확장 할 때도 다른 의존성 고려 안하고 늘리면 된다.
2. 안정성 개선
   - Raft 프로토콜을 사용해 로그 복제, 리더 선출, 메타데이터 변경 등을 효과적으로 처리할 수 있게 되었다.
   - 장애 발생시 리더 선출을 내부에서 직접 수행하기 때문에 Zookeeper 때보다 더 빠르게 선출할 수 있고, 이는 높은 가용성을 유지하는 데 도움이 된다.

이렇게 놓고 보니 장점이 더 많아졌다기 보다는 기존의 문제들을 많이 해결, 개선 한 느낌이다

### 모니터링은 어떻게 했나요?


Prometheus와 Grafana 두 개를 같이 사용했다.
이유는 둘의 역할이 달라서 인데 

Prometheus 얘는 Kafka Exporter를 통해 Kafka 브로커들의 데이터를 가져오는 역할이다.

물론 시각화를 할 수도 있긴 한데 좀 부족한 느낌이기는 하다.

이렇게 시각화가 부족한 부분을 Grafana로 채워주기로 결정했기에 Prometheus와 Grafana 두 개를 같이 사용한 것이다.

### 부하 테스트

저렇게 모니터링 환경 구축까지 다 해놓고 나니까 문득 든 생각이

> 음.. 저 Kafka Cluster가 제대로 구축 된게 맞나? 죽으면 안되는데

Airflow Dag 몇 개 데이터 스트리밍 하는 건 클러스터가 아니여도 별 문제가 없기에 우리는 저 클러스터가 과연 잘 돌아가는지 부하 테스트를 진행해 보기로 했다.

테스트 자체는 단순하다.

Kafka에 엄청나게 많은 데이터를 밀어넣었을 때 클러스터가 죽지 않고 문제없이 데이터를 잘 스트리밍 해야 한다.

테스트 방식은 다음 과 같다.

1. 특정 시간(오후 3시 쯤)에 Airflow Dag를 전부 1분 단위로 바꾸고 실행한다.
2. producer쪽 코드에 반복문을 건다.
   - API Call Limit가 있었기 때문에 API 쪽은 못했고, 대신에 producer쪽에 for문을 걸어서 부하 테스트를 진행했다.
   - news 데이터는 content가 html 통째로 넘겨주기 때문에 데이터 양이 작지는 않아서 꽤 유의미 할 것이라고 생각했다.![kafka producer 관련 코드에 for문 추가](https://github.com/user-attachments/assets/5226db4a-32e3-4a22-a9a9-8e859f6cef7b)
3. 한 명 화면 공유 해서 다 같이 지켜본다.

t2.xlarge(4 cores, 16GB RAM) 인스턴스 3개니까 총 12 cores 48GB 램인 것인데
인스턴스 갯수 제한이 있었기에 다른 앱들도 띄워두긴 했으나 생각보다 사양이 부족해 보이지는 않았기 때문에 뭐.. 문제 없겠지? 라는 생각을 했는데


### 이 앞. 문제있다.


우선 각 토픽별로 데이터가 얼마나 쌓이는지를 우선 모니터링 하고 있었다.

그런데 인스턴스가 점점 느려지더니 문제가 생겼다.

### 아 파티션 제대로 안 나눴다.

![인스턴스 스토리지가 부족한 사진](https://github.com/user-attachments/assets/0beb7f55-ffd9-4f76-8820-0a39b5768be3)
여러 토픽들이 전부 특정 파티션에 몰려서 3개의 인스턴스 중 2번 인스턴스의 스토리지가 빠르게 차오르기 시작했다.

순식간에 80GB를 채우고 쭉쭉 올라가고 있었다.
그리고 스토리지의 읽기쓰기 속도의 한계 때문에 데이터를 즉시 다 저장하지 못했기에

Airflow Dag job이 끝나기 전에 계속 실행돼서 심한건 job이 20개 넘게 밀려버렸다.

### 어 메모리 부족한데?

이건 안일했다고 봐야 하는데

실습 때 쓸 인스턴스가 3개로 제한되어 있었기에 거기에 우리가 쓸 앱을 전부 띄워야 했었다.

근데 Elastic Search가 생각보다 메모리를 많이 먹었는데, 이 상태에서 부하테스트를 걸어버리니까 그대로 죽었다.


### 결과
![kafka 모니터링 중인 Grafana Dashboard 사진](https://github.com/user-attachments/assets/bbcff7a8-a87a-4de0-b837-57fcae08b088)

차트를 보면 중간에 뚝 끊긴 부분이 있다.

저 때 Kafka가 죽었다.

죽은 걸 확인하고 나서 약간 신기했다.

원인 파악을 마치고 나서 한 일은

1. 파티션 추가
   - 특정 파티션에 모든 topic 데이터가 몰리는 문제가 있었기에 적절히 파티션을 추가하고, docker container에 접속해서 너무 많이 쌓인 topic data를 삭제했다.
   - 추후 다시 부하테스트 했을 때는 인스턴스 3개에 topic 데이터가 분산저장 되는 것을 확인할 수 있었다.
2. 메모리 제한 추가
   - Elastic Search와 Kibana docker compose 파일에 적절히 메모리 제한 하는 환경변수를 설정해주었다.
   - 나중아 알았는데 Spark도 제한 안 걸면 8GB 정도 쓰길래 Spark도 제한을 적절히 걸어주었다.

위와 같이 수정한 이후에는 부하테스트를 다시 진행해도 문제없이 데이터를 다 받아내었다. (야호) 

그리고 dag에 for문을 걸어놔서 그런지 Airflow도 생각보다 cpu 자원을 많이 사용하는 것 같다.

이번 프로젝트에서는 못 했지만, Airflow Dag가 엄청 많아지면 Kubernetes로 옮겨야 겠다는 생각도 해 보았다. 


### 부족했던 부분?

이번 프로젝트 에서는 Kafka를 좀 딥하게 사용해 보기로 했어서 Kafka 위주로 모니터링 했지만 추후에는 다른 앱들도 모니터링 해보면 좋을 것 같다.

그리고 설령 Kafka가 죽더라도 데이터가 손실되지 않기 위해 Replication, ISR, acks 설정 등을 더 공부해서 안정성을 더 높여봐야 겠다.

그리고 캐싱, 큐 기능을 잘 활용해서 kafka 성능을 최적화 하는 방법도 알아봐야 한다.

이제 다음으로 넘어가 보자.

## Spark를 굳이 써야 했을까..?

![spark cluster webui](https://github.com/user-attachments/assets/fd2be724-80ce-4ee5-bb0b-7f2ca51565fc)

Kafka에서 스트리밍 된 데이터를 전처리 하기 위해 Spark Cluster를 구축했다.

하지만 제목을 보다시피 나중에 보니 얘를 굳이 사용했어야 했나 싶다.

사용 할만한 이유는 충분했다고 생각 하는데 생각보다 스팀 쪽에서 준 데이터들이 잘 정제해서 준 느낌이여서 실제로는 Elastic Search에 있는 Kafka Connector를 사용해 바로 데이터를 넣거나

```
for game_name, game_id in GAMES.items():
    player_count = get_current_players(game_id)
    key = game_name  # 게임 이름을 키로 사용
    value = Json.dumps({
        'game': game_name,
        'player_count': player_count,
        'timestamp': current_time  # 현재 시간을 추가
    })  # 게임 이름, 플레이어 수, 타임스탬프를 Json으로 변환
```

이런식으로 간단하게만 필요한 값 들을 추가했다.

프로젝트의 규모를 봤을 때 Spark Cluster를 구축하는 게 오버엔지니어링 이였던 것 같다.

아니면 logstash 정도로 마무리 했던가..

그래서 더 아쉬웠던 것 같다.

프로젝트 요구사항, 그리고 먼저 API 데이터 들을 보면서 데이터 전처리 할 만한게 있나 살펴보고 결정했어야 했는데 단순히 Spark로 전처리 해보자! 라는 생각만 들었던 것 같다.

물론 기존에 학습했던 Spark를 실제 데이터 파이프라인에서 활용하며 공부해 보는 목적도 있긴 했지만 오버엔지니어링 이라는 사실은 변하지 않는다.

다음에는 파이프라인 구조 설계할 때 좀 더 신경을 써야겠다.


## Elastic Search & Kibana

스팀 API에서 제공하는 데이터는 Json 데이터였고, 우리는 이 데이터를 가지고 바로 시각화 해서 보고 싶었기 때문에 **Elastic Search & Kibana** 라는 기술스택을 선택하게 되었고


1. 검색 기능이 좋다
   - 분산형 검색 & 분석 엔진이기에 Json 문서를 인덱싱하고 실시간으로 빠르게 검색할 수 있다.
   - Steam API 데이터들은 거의 다 Json이기 때문에 우리가 구축하려 하는 파이프라인에 적합한 DB라고 판단했다.
2. Kibana와 Elastic Search를 통합해서 실시간 대시보드 및 시각화를 제공해준다.

그렇기에 이 둘을 선택한 뒤 스팀에서 받아온 데이터 들을 Elastic Search에 저장했다.

![Kibana Index Management Page 사진](https://github.com/user-attachments/assets/44dd63be-1fdc-44a5-9586-3d9b2ff91bfc)

Kibana 시각화 사진은 준비하지 못했다.

프로젝트 마감, 부하테스트 내용 발표준비 하느라 정작 중요한 걸 빼먹어버렸다.

그리고 인스턴스도 사라지기 때문에 아쉽다.. 해보고 싶었던게 많았기에 시간이 부족해서 더 아쉬웠다.


## 리뷰

우선 이어드림 스쿨 과정을 반 정도 열심히 달려온 것 같다.

중간에 소규모 팀 프로젝트를 여러개 했었지만, 이번에는 팀원들 열정이 좋아서 진행하는데 재밌게 했다.

그리고 지금까지 이어드림 스쿨 팀 프로젝트를 할 때 마다 전부 리더 역할을 했다.

원래 이런 성격은 아니긴 한데 개발 관련 지식을 잘 모르시는 분들이 많았기에 매 프로젝트 마다 리더 역할을 하며 전체적으로 프로젝트를 이끌어 가고, 잘 모르시는 분들을 도와주면서 인간적으로도 더 성장한 것 같다.

블로그 글도 원래 쓰고 싶었는데 쓸 만한 지식을 갖추고 있다고 생각하지 않아서 여태 쓰지 못했다. (그냥 뭐라도 쓸 걸)

그냥 Kafka 쓰면 좋은 이유, Spark가 뭘까? 이런 간단한거 말고 내가 해당 기술스택을 사용하면서 깊게 생각해본 것이나 어려운 문제를 해결한 경험 같은 양질의 글을 작성하고 싶었다.

근데 지금까지는 내가 별로 알고 있는게 많지도 않았고, 단순한 정보성 글 밖에 못 쓸 것 같아서 못 하고 있었고, 파이프라인 구축 프로젝트도 진행해봤기 때문에 이제부터는 잘 써보려고 한다.
